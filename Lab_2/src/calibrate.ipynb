{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Intrinsic Calibration\n",
    "\n",
    "In this notebook we will:\n",
    "1. Load the detected corner data from `captured_points/corners.npz`.\n",
    "2. Run either checkerboard or ChArUco calibration.\n",
    "3. Examine and plot reprojection errors.\n",
    "4. Save the resulting camera matrix **K** and distortion coefficients **d** to `captured_points/intrinsics.yml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import yaml\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make plots appear inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Paths (relative to notebook location)\n",
    "DATA_DIR = os.path.join('..', 'captured_points')\n",
    "NPZ_FILE = os.path.join(DATA_DIR, 'corners.npz')\n",
    "YAML_OUT = os.path.join(DATA_DIR, 'intrinsics.yml')\n",
    "\n",
    "print(\"Corners file:\", NPZ_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(NPZ_FILE, allow_pickle=True)\n",
    "print(\"Keys in NPZ:\", list(data.keys()))\n",
    "\n",
    "# Determine calibration mode\n",
    "if 'objpoints' in data:\n",
    "    mode = 'checker'\n",
    "elif 'corners' in data:\n",
    "    mode = 'charuco'\n",
    "else:\n",
    "    raise ValueError(\"Unrecognized data format in corners.npz\")\n",
    "print(f\"Calibration mode: {mode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the forward projection\n",
    "\n",
    "$$\n",
    "\\underbrace{\\begin{bmatrix}u\\\\v\\\\1\\end{bmatrix}}_{\\text{pixel}}\n",
    "=\n",
    "\\underbrace{\n",
    "\\begin{bmatrix}\n",
    "f_x & 0   & c_x\\\\\n",
    "0   & f_y & c_y\\\\\n",
    "0   & 0   & 1\n",
    "\\end{bmatrix}}_{K}\n",
    "\\Bigl(1 + \\text{distort}(\\mathbf{x}_n)\\Bigr)\n",
    "\\underbrace{\\frac{1}{Z_c}\n",
    "\\begin{bmatrix}\n",
    "X_c\\\\Y_c\\\\1\n",
    "\\end{bmatrix}}_{\\mathbf{x}_n}\n",
    "$$\n",
    "\n",
    "*We'll estimate $K$ and the distortion parameters by minimising the reprojection error $e_i = \\lVert x_i - \\hat{x}_i\\rVert$.*\n",
    "\n",
    "OpenCV provides highly optimized functions for camera calibration. The `cv2.calibrateCamera()` function (for checkerboards) and `cv2.aruco.calibrateCameraCharuco()` function (for ChArUco boards) use nonlinear optimization to find the camera matrix $K$ and distortion coefficients that minimize the reprojection error across all calibration frames.\n",
    "\n",
    "The code below performs camera calibration using either:\n",
    "1. Standard checkerboard calibration (using `cv2.calibrateCamera()`)\n",
    "2. ChArUco board calibration (using `cv2.aruco.calibrateCameraCharuco()`)\n",
    "\n",
    "The calibration returns:\n",
    "- `ret`: Mean reprojection error in pixels (lower is better)\n",
    "- `K`: The 3×3 camera intrinsic matrix\n",
    "- `dist`: Distortion coefficients (k₁, k₂, k₃, p₁, p₂, ...)\n",
    "- `rvecs`, `tvecs`: Rotation and translation vectors for each calibration frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = tuple(data[\"img_shape\"])        # (width, height)\n",
    "\n",
    "if mode == \"checker\":\n",
    "    objpoints = data[\"objpoints\"]\n",
    "    imgpoints = data[\"imgpoints\"]\n",
    "\n",
    "    ret, K, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        objpoints, imgpoints, img_shape, None, None\n",
    "    )\n",
    "\n",
    "elif mode == \"charuco\":\n",
    "    corners = data[\"corners\"]\n",
    "    ids     = data[\"ids\"]\n",
    "\n",
    "    # modern names\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "    board      = cv2.aruco.CharucoBoard(\n",
    "        (5, 7),           # number of chessboard squares  (nx, ny)\n",
    "        0.03,             # square side length\n",
    "        0.022,            # marker side length\n",
    "        aruco_dict\n",
    "    )\n",
    "\n",
    "    ret, K, dist, rvecs, tvecs = cv2.aruco.calibrateCameraCharuco(\n",
    "        charucoCorners=corners,\n",
    "        charucoIds=ids,\n",
    "        board=board,\n",
    "        imageSize=img_shape,          # (width, height)\n",
    "        cameraMatrix=None,\n",
    "        distCoeffs=None\n",
    "    )\n",
    "\n",
    "print(f\"Mean reprojection error: {ret:.4f} px\")\n",
    "print(\"Camera matrix K:\\n\", K)\n",
    "print(\"Distortion coeffs d:\\n\", dist.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate errors as in your code\n",
    "errors = []\n",
    "if mode == 'checker':\n",
    "    # project each object point into the image\n",
    "    for objp, imgp, rvec, tvec in zip(objpoints, imgpoints, rvecs, tvecs):\n",
    "        proj, _ = cv2.projectPoints(objp, rvec, tvec, K, dist)\n",
    "        err = np.linalg.norm(proj.reshape(-1,2) - imgp.reshape(-1,2), axis=1)\n",
    "        errors.extend(err)\n",
    "elif mode == 'charuco':\n",
    "    # project all ChArUco corners\n",
    "    for ch_corners, ch_ids, rvec, tvec in zip(corners, ids, rvecs, tvecs):\n",
    "        objp = board.getChessboardCorners()[ch_ids.flatten(), :]   # 3-D pts\n",
    "        proj, _ = cv2.projectPoints(objp, rvec, tvec, K, dist)\n",
    "        err = np.linalg.norm(\n",
    "            proj.reshape(-1, 2) - ch_corners.reshape(-1, 2), axis=1\n",
    "        )\n",
    "        errors.extend(err)\n",
    "errors = np.array(errors)\n",
    "print(f\"Total points: {len(errors)}, mean error = {errors.mean():.4f} px\")\n",
    "\n",
    "# Gather radial distances and corresponding errors\n",
    "radial = []\n",
    "errs = []\n",
    "cx, cy = K[0,2], K[1,2]\n",
    "\n",
    "if mode == 'checker':\n",
    "    for objp, imgp, rvec, tvec in zip(objpoints, imgpoints, rvecs, tvecs):\n",
    "        proj, _ = cv2.projectPoints(objp, rvec, tvec, K, dist)\n",
    "        flat_proj = proj.reshape(-1,2)\n",
    "        flat_imgp = imgp.reshape(-1,2)\n",
    "        for p_proj, p_img in zip(flat_proj, flat_imgp):\n",
    "            radial.append(np.linalg.norm(p_img - np.array([cx, cy])))\n",
    "            errs.append(np.linalg.norm(p_proj - p_img))\n",
    "elif mode == 'charuco':\n",
    "    for ch_corners, ch_ids, rvec, tvec in zip(corners, ids, rvecs, tvecs):\n",
    "        objp = board.getChessboardCorners()[ch_ids.flatten(), :]\n",
    "        proj, _ = cv2.projectPoints(objp, rvec, tvec, K, dist)\n",
    "        flat_proj = proj.reshape(-1, 2)\n",
    "        flat_corn = ch_corners.reshape(-1, 2)\n",
    "        for p_proj, p_corn in zip(flat_proj, flat_corn):\n",
    "            radial.append(np.linalg.norm(p_corn - np.array([cx, cy])))\n",
    "            errs.append(np.linalg.norm(p_proj - p_corn))\n",
    "radial = np.array(radial)\n",
    "errs = np.array(errs)\n",
    "\n",
    "# Create a combined figure with two subplots side by side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Plot 1: Histogram\n",
    "ax1.hist(errors, bins=50, range=(0, np.percentile(errors, 99)))\n",
    "ax1.set_title(\"Reprojection Error Distribution\")\n",
    "ax1.set_xlabel(\"Error (px)\")\n",
    "ax1.set_ylabel(\"Number of points\")\n",
    "ax1.grid(True)\n",
    "\n",
    "# Plot 2: Scatter plot\n",
    "ax2.scatter(radial, errs, s=2, alpha=0.3)\n",
    "ax2.set_title(\"Radial Error vs. Distance from Center\")\n",
    "ax2.set_xlabel(\"Radius (px)\")\n",
    "ax2.set_ylabel(\"Error (px)\")\n",
    "ax2.grid(True)\n",
    "\n",
    "# Adjust layout and show\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib = {\n",
    "    'K': {'data': K.tolist(), 'rows':3, 'cols':3},\n",
    "    'D': {'data': dist.ravel().tolist(), 'rows':1, 'cols':len(dist.ravel())}\n",
    "}\n",
    "with open(YAML_OUT, 'w') as f:\n",
    "    yaml.dump(calib, f)\n",
    "print(f\"Saved intrinsics to {YAML_OUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay: Detected vs. Reprojected Corners\n",
    "\n",
    "Now that we have our camera matrix **K** and distortion **d**, let's take one example image and:\n",
    "\n",
    "1. Plot the **detected** corners in **green**.  \n",
    "2. Project the corresponding 3D object points back into the image and plot these **reprojected** corners in **red**.  \n",
    "\n",
    "Ideally they should coincide. Large offsets highlight local calibration errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the middle image for visualization\n",
    "img_files = sorted(os.path.join('..','data',f) for f in os.listdir('../data') if f.endswith('.jpg'))\n",
    "valid_files = data['valid_files']\n",
    "img_idx = len(valid_files)//3\n",
    "viz_path = valid_files[img_idx]\n",
    "viz_img = cv2.imread(os.path.join('..','data', os.path.basename(viz_path)))\n",
    "gray_viz = cv2.cvtColor(viz_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# retrieve one set of object & image points for checkerboard, or charuco\n",
    "if mode == 'checker':\n",
    "    objp = objpoints[img_idx]         # 3D points\n",
    "    imgp = imgpoints[img_idx].reshape(-1,2)  # detected 2D points\n",
    "    rvec, tvec = rvecs[img_idx], tvecs[img_idx]\n",
    "elif mode == 'charuco':\n",
    "    # convert to 3D by adding Z=0\n",
    "    ch_corners = corners[img_idx]  # detected corners\n",
    "    ch_ids = ids[img_idx]          # corresponding IDs\n",
    "    \n",
    "    # Recreate the board definition\n",
    "    aruco_dict = cv2.aruco.getPredefinedDictionary(cv2.aruco.DICT_4X4_50)\n",
    "    board = cv2.aruco.CharucoBoard(\n",
    "            (5, 7),          # (nx, ny)\n",
    "            0.03,            # square side\n",
    "            0.022,           # marker side\n",
    "            aruco_dict\n",
    "        )\n",
    "    \n",
    "    # Get 3D object points from the board definition\n",
    "    objp = board.getChessboardCorners()[ch_ids.flatten()]\n",
    "    imgp = ch_corners.reshape(-1, 2)\n",
    "    rvec, tvec = rvecs[img_idx], tvecs[img_idx]\n",
    "\n",
    "# project objp back into pixel space\n",
    "proj_pts, _ = cv2.projectPoints(objp, rvec, tvec, K, dist)\n",
    "proj_pts = proj_pts.reshape(-1,2)\n",
    "\n",
    "# overlay\n",
    "vis = viz_img.copy()\n",
    "for (x,y), (u,v) in zip(imgp, proj_pts):\n",
    "    cv2.circle(vis, (int(x),int(y)), 4, (0,255,0), 2)  # green = detected\n",
    "    cv2.circle(vis, (int(u),int(v)), 3, (0,0,255), 2)  # red   = reprojected\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Green: detected corners     Red: reprojected corners\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Are We Comparing Between Green and Red Dots?\n",
    "\n",
    "This visualization shows two sets of 2D points plotted over the image:\n",
    "\n",
    "- **Green dots**: These are **detected image points** — pixel locations where the checkerboard corners were found using OpenCV's `findChessboardCorners()` (or ChArUco equivalent). These are your \"ground truth\" 2D detections.\n",
    "- **Red dots**: These are **reprojected points** — predicted pixel positions obtained by projecting the known 3D board corners using your estimated camera intrinsics and extrinsics. These come from `cv2.projectPoints()`.\n",
    "\n",
    "---\n",
    "\n",
    "### Step-by-Step Pipeline\n",
    "\n",
    "#### 1. **Detect corners in the image (green dots)**\n",
    "\n",
    "You detect 2D points in the captured image using:\n",
    "```python\n",
    "ret, corners = cv2.findChessboardCorners(gray, pattern_size, ...)\n",
    "```\n",
    "\n",
    "This gives you a list of 2D image coordinates:\n",
    "$$\\{(u_i, v_i)\\}_{i=1}^{N}$$\n",
    "\n",
    "#### 2. **Define the known 3D object points**\n",
    "\n",
    "For a checkerboard with num_x × num_y squares, there are (num_x - 1) × (num_y - 1) inner corners. We define these points on a 2D plane (Z = 0), scaled by the square size:\n",
    "$$\\{(X_i, Y_i, 0)\\}_{i=1}^{N}$$\n",
    "\n",
    "#### 3. **Calibrate the camera**\n",
    "\n",
    "You solve for the camera intrinsics (K), distortion coefficients (d), and per-frame extrinsics (R, t) using:\n",
    "\n",
    "```python\n",
    "cv2.calibrateCamera(...)\n",
    "```\n",
    "\n",
    "This fits the projection model:\n",
    "$$\\mathbf{P} = \\mathbf{K} [\\mathbf{R} \\mid \\mathbf{t}]$$\n",
    "and distortion model (radial + tangential) by minimizing:\n",
    "$$\\sum_{i} \\left| (u_i, v_i) - \\Pi(\\mathbf{K}, \\mathbf{R}, \\mathbf{t}; X_i) \\right|^2$$\n",
    "\n",
    "#### 4. **Reproject the 3D points into image space (red dots)**\n",
    "\n",
    "Using the estimated calibration parameters, you reproject the known 3D object points into the image:\n",
    "\n",
    "```python\n",
    "proj_pts = cv2.projectPoints(objp, rvec, tvec, K, dist)\n",
    "```\n",
    "\n",
    "This yields predicted 2D points:\n",
    "$$\\{(\\hat{u}_i, \\hat{v}_i)\\}_{i=1}^{N}$$\n",
    "\n",
    "---\n",
    "\n",
    "### Why Are the Red and Green Dots Different?\n",
    "\n",
    "They won't perfectly overlap, because the model is an approximation and the input data is noisy:\n",
    "- **Detection noise**: Even subpixel corner detection is affected by blur, lighting, and resolution.\n",
    "- **Model mismatch**: The distortion model may not fully capture the lens behavior, especially at the periphery.\n",
    "- **Limited coverage**: If certain viewpoints (e.g. tilted, close-up, or edge shots) are missing, the model is under-constrained in those areas.\n",
    "- **Numerical approximation**: Optimization has residual error even after convergence.\n",
    "\n",
    "---\n",
    "\n",
    "### Reprojection Error\n",
    "\n",
    "The difference between red and green dots is called the reprojection error — the distance between where the model says a corner should be and where it was actually detected.\n",
    "- **Good calibration**: < 0.5 px mean reprojection error\n",
    "- **Precision calibration**: < 0.3 px\n",
    "- **Bad calibration**: > 1.0 px — likely poor data, blur, or mismatch in square size or pattern\n",
    "\n",
    "---\n",
    "\n",
    "### How to Improve Alignment\n",
    "- **Ensure accurate board specs**: match pattern_size to the printed board.\n",
    "- **Use consistent indexing**: Make sure you're overlaying red/green dots for the same image.\n",
    "- **Capture diverse viewpoints**: Boards at various angles, distances, and edge positions.\n",
    "- **Drop outlier images**: Recompute calibration without frames that have large reprojection error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try-it-yourself ✏️\n",
    "\n",
    "This interactive visualization has two tabs to explore different camera parameters:\n",
    "\n",
    "### Tab 1: Distortion Parameters\n",
    "Use the sliders to perturb the **radial (k₁, k₂, k₃)** and **tangential (p₁, p₂)** distortion\n",
    "coefficients and watch how the *red* re-projected corners shift relative to the *green*\n",
    "detected ones.\n",
    "\n",
    "### Tab 2: Intrinsic Parameters\n",
    "Experiment with the camera's intrinsic parameters **focal length (fx, fy)** and **principal point (cx, cy)** \n",
    "to see how they affect the projection geometry.\n",
    "\n",
    "* Questions to think about\n",
    "1. When you nudge **k₁** positively, which image region moves the most?\n",
    "2. Which coefficient mainly shears the pattern rather than radial-expands it?\n",
    "3. How does changing **fx** differ from changing **fy** in terms of projection effects?\n",
    "4. What happens to the projection when you shift the principal point (cx, cy)?\n",
    "5. At what parameter values do the re-projected dots best coincide with the detections?\n",
    "\n",
    "Remember: In a real calibration workflow, we optimize both intrinsic and distortion parameters \n",
    "to minimize the re-projection error (pixel distance between the two sets of dots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q ipywidgets > /dev/null 2>&1\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive, HBox, VBox, Button, Tab\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def make_slider(label, value, coarse_factor=3.0, fine_step=1e-3, hard_max=5.0):\n",
    "    \"\"\"\n",
    "    Return a FloatSlider centred at value with range determined by coarse_factor.\n",
    "    \"\"\"\n",
    "    span = max(abs(value) * coarse_factor, 0.05)\n",
    "    span = min(span, hard_max)\n",
    "    return widgets.FloatSlider(\n",
    "        value=float(value),\n",
    "        min=value-span,\n",
    "        max=value+span,\n",
    "        step=fine_step,\n",
    "        description=label\n",
    "    )\n",
    "\n",
    "# --- Distortion parameter sliders ---\n",
    "k1_slider = make_slider('k₁', dist[0][0])\n",
    "k2_slider = make_slider('k₂', dist[0][1])\n",
    "p1_slider = make_slider('p₁', dist[0][2], coarse_factor=3.0, fine_step=1e-4, hard_max=0.2)\n",
    "p2_slider = make_slider('p₂', dist[0][3], coarse_factor=3.0, fine_step=1e-4, hard_max=0.2)\n",
    "k3_slider = make_slider('k₃', dist[0][4], coarse_factor=1.5, fine_step=1e-2, hard_max=10)\n",
    "\n",
    "# --- Intrinsic parameter sliders ---\n",
    "# fx_slider = make_slider('fx', K[0,0], coarse_factor=0.2, fine_step=5.0)\n",
    "# fy_slider = make_slider('fy', K[1,1], coarse_factor=0.2, fine_step=5.0)\n",
    "# cx_slider = make_slider('cx', K[0,2], coarse_factor=0.2, fine_step=1.0)\n",
    "# cy_slider = make_slider('cy', K[1,2], coarse_factor=0.2, fine_step=1.0)\n",
    "fx_slider = widgets.FloatSlider(\n",
    "    value=float(K[0,0]),\n",
    "    min=K[0,0]*0.8,  # 20% decrease\n",
    "    max=K[0,0]*1.2,  # 20% increase\n",
    "    step=1.0,        # Finer step\n",
    "    description='fx',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "fy_slider = widgets.FloatSlider(\n",
    "    value=float(K[1,1]),\n",
    "    min=K[1,1]*0.8,\n",
    "    max=K[1,1]*1.2,\n",
    "    step=1.0,\n",
    "    description='fy',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# For principal point - wider range with finer steps\n",
    "cx_slider = widgets.FloatSlider(\n",
    "    value=float(K[0,2]),\n",
    "    min=K[0,2]-50,\n",
    "    max=K[0,2]+50,\n",
    "    step=0.5,\n",
    "    description='cx',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "cy_slider = widgets.FloatSlider(\n",
    "    value=float(K[1,2]),\n",
    "    min=K[1,2]-50,\n",
    "    max=K[1,2]+50,\n",
    "    step=0.5,\n",
    "    description='cy',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# --- Reset buttons ---\n",
    "reset_dist_btn = Button(description=\"Reset Distortion\", tooltip=\"Restore calibrated distortion values\")\n",
    "reset_intr_btn = Button(description=\"Reset Intrinsics\", tooltip=\"Restore calibrated intrinsic values\")\n",
    "\n",
    "def reset_dist_sliders(_):\n",
    "    for s, val in zip([k1_slider, k2_slider, p1_slider, p2_slider, k3_slider], dist[0]):\n",
    "        s.value = float(val)\n",
    "        \n",
    "def reset_intr_sliders(_):\n",
    "    fx_slider.value = float(K[0,0])\n",
    "    fy_slider.value = float(K[1,1])\n",
    "    cx_slider.value = float(K[0,2])\n",
    "    cy_slider.value = float(K[1,2])\n",
    "    \n",
    "reset_dist_btn.on_click(reset_dist_sliders)\n",
    "reset_intr_btn.on_click(reset_intr_sliders)\n",
    "\n",
    "# --- Projection visualization functions ---\n",
    "def show_projection_dist(k1, k2, p1, p2, k3):\n",
    "    \"\"\"Visualize effects of distortion parameters\"\"\"\n",
    "    d = np.array([k1, k2, p1, p2, k3], dtype=np.float64)\n",
    "    proj_pts, _ = cv2.projectPoints(objp, rvec, tvec, K, d)\n",
    "    proj_pts = proj_pts.reshape(-1, 2)\n",
    "\n",
    "    vis = viz_img.copy()\n",
    "    for (x, y), (u, v) in zip(imgp, proj_pts):\n",
    "        cv2.circle(vis, (int(x), int(y)), 4, (0, 255, 0), 2)   # detected\n",
    "        cv2.circle(vis, (int(u), int(v)), 3, (0, 0, 255), 2)   # re-projected\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Distortion Parameter Effects\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def show_projection_intr(fx, fy, cx, cy):\n",
    "    \"\"\"Visualize effects of intrinsic parameters\"\"\"\n",
    "    # Create modified camera matrix\n",
    "    modified_K = K.copy()\n",
    "    modified_K[0,0] = fx  # focal length x\n",
    "    modified_K[1,1] = fy  # focal length y\n",
    "    modified_K[0,2] = cx  # principal point x\n",
    "    modified_K[1,2] = cy  # principal point y\n",
    "    \n",
    "    proj_pts, _ = cv2.projectPoints(objp, rvec, tvec, modified_K, dist)\n",
    "    proj_pts = proj_pts.reshape(-1, 2)\n",
    "\n",
    "    vis = viz_img.copy()\n",
    "    for (x, y), (u, v) in zip(imgp, proj_pts):\n",
    "        cv2.circle(vis, (int(x), int(y)), 4, (0, 255, 0), 2)   # detected\n",
    "        cv2.circle(vis, (int(u), int(v)), 3, (0, 0, 255), 2)   # re-projected\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Intrinsic Parameter Effects\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# --- Create interactive widgets ---\n",
    "interactive_dist = interactive(\n",
    "    show_projection_dist,\n",
    "    k1=k1_slider, k2=k2_slider, k3=k3_slider,\n",
    "    p1=p1_slider, p2=p2_slider\n",
    ")\n",
    "\n",
    "interactive_intr = interactive(\n",
    "    show_projection_intr,\n",
    "    fx=fx_slider, fy=fy_slider, cx=cx_slider, cy=cy_slider\n",
    ")\n",
    "\n",
    "# --- Create tabbed interface ---\n",
    "tab = Tab()\n",
    "tab.children = [\n",
    "    VBox([HBox([reset_dist_btn]), interactive_dist]),\n",
    "    VBox([HBox([reset_intr_btn]), interactive_intr])\n",
    "]\n",
    "tab.set_title(0, 'Distortion Parameters')\n",
    "tab.set_title(1, 'Intrinsic Parameters')\n",
    "\n",
    "style = \"\"\"\n",
    "    <style>\n",
    "    .jupyter-widgets.widget-tab .p-TabBar-tabLabel {\n",
    "        color: black;\n",
    "        font-weight: bold;\n",
    "    }\n",
    "    </style>\n",
    "\"\"\"\n",
    "display(HTML(style))\n",
    "display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do the distortion coefficients actually do?\n",
    "\n",
    "| Symbol | Name | Typical visual effect  |\n",
    "| ------ | ---- | ---------------------  |\n",
    "| **k₁** | 1st radial distortion | Barrel / pincushion curvature that grows ∝ *r²* |\n",
    "| **k₂** | 2nd radial distortion | Higher-order tweak that exaggerates the edge warping introduced by **k₁** |\n",
    "| **k₃** | 3rd radial distortion | Cubic radial term—dominates in the extreme corners when **k₁**, **k₂** can’t fully correct |\n",
    "| **p₁** | Tangential (x-shear) | Skews dots left/right when the lens & sensor are not perfectly parallel |\n",
    "| **p₂** | Tangential (y-shear) | Skews dots up/down under the same mis-alignment |\n",
    "\n",
    "*Here \\(r^2 = x^2 + y^2\\) is the squared, normalised image-plane radius.*\n",
    "\n",
    "**How to interpret the sliders**\n",
    "\n",
    "* If the red dots form a symmetric bulge or pinch, adjust **k₁**, **k₂**, or **k₃** (radial terms).  \n",
    "* If they lean or shear in one direction, tweak **p₁** or **p₂** (tangential terms).  \n",
    "* Press **Reset ↺** any time to return to the calibrated optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side-by-side: Original vs. Undistorted\n",
    "\n",
    "Next, we’ll undistort the same image using our intrinsics and plot it alongside the original.  \n",
    "Notice how straight lines near the border are “pulled” back into alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = gray_viz.shape\n",
    "newK, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w,h), 1)\n",
    "undist = cv2.undistort(viz_img, K, dist, None, newK)\n",
    "\n",
    "# compute difference image\n",
    "diff = cv2.absdiff(viz_img, undist)\n",
    "# enhance difference visibility\n",
    "diff_enhanced = cv2.convertScaleAbs(diff, alpha=5.0)  # amplify differences\n",
    "\n",
    "# plot side by side with the difference\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "axes[0].imshow(cv2.cvtColor(viz_img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cv2.cvtColor(undist, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(\"Undistorted\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(cv2.cvtColor(diff_enhanced, cv2.COLOR_BGR2RGB))\n",
    "axes[2].set_title(\"Difference (Enhanced)\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distortion Vector Field\n",
    "\n",
    "Let’s visualize how each pixel is displaced by the distortion model.  \n",
    "We’ll sample a coarse grid (e.g. every 40 px), undistort those points,  \n",
    "and draw arrows from original → undistorted positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grid of points\n",
    "stride = 40\n",
    "Y, X = np.mgrid[0:h:stride, 0:w:stride].reshape(2,-1)\n",
    "grid = np.vstack([X, Y]).T.astype(np.float32).reshape(-1,1,2)\n",
    "\n",
    "# undistort these grid points\n",
    "und_grid = cv2.undistortPoints(grid, K, dist, P=K).reshape(-1,2)\n",
    "\n",
    "# plot arrows on the original image\n",
    "field_vis = viz_img.copy()\n",
    "for (x,y), (u,v) in zip(grid.reshape(-1,2), und_grid):\n",
    "    cv2.arrowedLine(field_vis, (int(x),int(y)), (int(u),int(v)),\n",
    "                    color=(255,0,0), thickness=1, tipLength=0.3)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(cv2.cvtColor(field_vis, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Distortion Vector Field (blue arrows)\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The arrows indicate the magnitude and direction of distortion across the field—longer arrows at the periphery reflect stronger barrel distortion.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Heatmap Across All Images\n",
    "\n",
    "Finally, let’s accumulate reprojection errors spatially over every image.  \n",
    "We’ll bin each projected point by its undistorted pixel location and color‐code the average error in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all reproj errors + undistorted locations\n",
    "all_u = []; all_v = []; all_e = []\n",
    "\n",
    "for i in range(len(rvecs)):\n",
    "    if mode == 'checker':\n",
    "        pts2d = imgpoints[i].reshape(-1,2)\n",
    "        objp_i = objpoints[i]\n",
    "    else:\n",
    "        pts2d  = corners[i].reshape(-1, 2)\n",
    "        objp_i = board.getChessboardCorners()[ids[i].flatten()]\n",
    "\n",
    "    # project and undistort\n",
    "    proj2d, _ = cv2.projectPoints(objp_i, rvecs[i], tvecs[i], K, dist)\n",
    "    proj2d = proj2d.reshape(-1, 2)\n",
    "    und2d  = cv2.undistortPoints(\n",
    "                 pts2d.reshape(-1, 1, 2), K, dist, P=K\n",
    "             ).reshape(-1, 2)\n",
    "\n",
    "    errs = np.linalg.norm(proj2d - pts2d, axis=1)\n",
    "    all_u.extend(und2d[:, 0]); all_v.extend(und2d[:, 1]); all_e.extend(errs)\n",
    "\n",
    "all_u = np.array(all_u); all_v = np.array(all_v); all_e = np.array(all_e)\n",
    "\n",
    "# bin into a heatmap\n",
    "nbin = 50\n",
    "xi = np.linspace(0, w, nbin)\n",
    "yi = np.linspace(0, h, nbin)\n",
    "heatmap, _, _ = np.histogram2d(all_v, all_u, bins=[yi, xi], weights=all_e)\n",
    "counts, _, _  = np.histogram2d(all_v, all_u, bins=[yi, xi])\n",
    "heatmap = np.divide(heatmap, counts, out=np.zeros_like(heatmap), where=counts>0)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(heatmap, origin='lower', extent=[0,w,0,h], cmap='hot')\n",
    "plt.colorbar(label='Mean reprojection error (px)')\n",
    "plt.title(\"Spatial Heatmap of Reprojection Error\")\n",
    "plt.xlabel(\"u (px)\"); plt.ylabel(\"v (px)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The heatmap shows where your calibration struggles most; hot regions near the border often point to insufficient distortion modeling or corner detection accuracy.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Next:**  \n",
    "- Use these intrinsics in `measure_object.py` to perform metric checks.  \n",
    "- Switch to the other board type (checker ↔ ChArUco) and compare mean errors.  \n",
    "- Commit `captured_points/intrinsics.yml` to GitHub for TA review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
