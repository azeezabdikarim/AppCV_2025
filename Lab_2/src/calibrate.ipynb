{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Intrinsic Calibration\n",
    "\n",
    "In this notebook we will:\n",
    "1. Load the detected corner data from `captured_points/corners.npz`.\n",
    "2. Run either checkerboard or ChArUco calibration.\n",
    "3. Examine and plot reprojection errors.\n",
    "4. Save the resulting camera matrix **K** and distortion coefficients **d** to `captured_points/intrinsics.yml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import yaml\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make plots appear inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Paths (relative to notebook location)\n",
    "DATA_DIR = os.path.join('..', 'captured_points')\n",
    "NPZ_FILE = os.path.join(DATA_DIR, 'corners.npz')\n",
    "YAML_OUT = os.path.join(DATA_DIR, 'intrinsics.yml')\n",
    "\n",
    "print(\"Corners file:\", NPZ_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(NPZ_FILE, allow_pickle=True)\n",
    "print(\"Keys in NPZ:\", list(data.keys()))\n",
    "\n",
    "# Determine calibration mode\n",
    "if 'objpoints' in data:\n",
    "    mode = 'checker'\n",
    "elif 'corners' in data:\n",
    "    mode = 'charuco'\n",
    "else:\n",
    "    raise ValueError(\"Unrecognized data format in corners.npz\")\n",
    "print(f\"Calibration mode: {mode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the forward projection\n",
    "\n",
    "$$\n",
    "\\underbrace{\\begin{bmatrix}u\\\\v\\\\1\\end{bmatrix}}_{\\text{pixel}}\n",
    "=\n",
    "\\underbrace{\n",
    "\\begin{bmatrix}\n",
    "f_x & 0   & c_x\\\\\n",
    "0   & f_y & c_y\\\\\n",
    "0   & 0   & 1\n",
    "\\end{bmatrix}}_{K}\n",
    "\\Bigl(1 + \\text{distort}(\\mathbf{x}_n)\\Bigr)\n",
    "\\underbrace{\\frac{1}{Z_c}\n",
    "\\begin{bmatrix}\n",
    "X_c\\\\Y_c\\\\1\n",
    "\\end{bmatrix}}_{\\mathbf{x}_n}\n",
    "$$\n",
    "\n",
    "*We'll estimate $K$ and the distortion parameters by minimising the reprojection error $e_i = \\lVert x_i - \\hat{x}_i\\rVert$.*\n",
    "\n",
    "OpenCV provides highly optimized functions for camera calibration. The `cv2.calibrateCamera()` function (for checkerboards) and `cv2.aruco.calibrateCameraCharuco()` function (for ChArUco boards) use nonlinear optimization to find the camera matrix $K$ and distortion coefficients that minimize the reprojection error across all calibration frames.\n",
    "\n",
    "The code below performs camera calibration using either:\n",
    "1. Standard checkerboard calibration (using `cv2.calibrateCamera()`)\n",
    "2. ChArUco board calibration (using `cv2.aruco.calibrateCameraCharuco()`)\n",
    "\n",
    "The calibration returns:\n",
    "- `ret`: Mean reprojection error in pixels (lower is better)\n",
    "- `K`: The 3×3 camera intrinsic matrix\n",
    "- `dist`: Distortion coefficients (k₁, k₂, p₁, p₂, k₃, ...)\n",
    "- `rvecs`, `tvecs`: Rotation and translation vectors for each calibration frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve common items\n",
    "img_shape = tuple(data['img_shape'])  # (width, height)\n",
    "\n",
    "if mode == 'checker':\n",
    "    objpoints = data['objpoints']\n",
    "    imgpoints = data['imgpoints']\n",
    "    ret, K, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        objpoints, imgpoints, img_shape, None, None\n",
    "    )\n",
    "elif mode == 'charuco':\n",
    "    corners = data['corners']\n",
    "    ids     = data['ids']\n",
    "    # recreate the board definition exactly as in detect_corners.py\n",
    "    aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_4X4_50)\n",
    "    board = cv2.aruco.CharucoBoard_create(5, 7, 0.03, 0.022, aruco_dict)\n",
    "    ret, K, dist, rvecs, tvecs = cv2.aruco.calibrateCameraCharuco(\n",
    "        corners, ids, board, img_shape, None, None\n",
    "    )\n",
    "\n",
    "print(f\"Mean reprojection error: {ret:.4f} px\")\n",
    "print(\"Camera matrix K:\\n\", K)\n",
    "print(\"Distortion coeffs d:\\n\", dist.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "\n",
    "if mode == 'checker':\n",
    "    # project each object point into the image\n",
    "    for objp, imgp, rvec, tvec in zip(objpoints, imgpoints, rvecs, tvecs):\n",
    "        proj, _ = cv2.projectPoints(objp, rvec, tvec, K, dist)\n",
    "        err = np.linalg.norm(proj.reshape(-1,2) - imgp.reshape(-1,2), axis=1)\n",
    "        errors.extend(err)\n",
    "elif mode == 'charuco':\n",
    "    # project all ChArUco corners\n",
    "    for ch_corners, ch_ids, rvec, tvec in zip(corners, ids, rvecs, tvecs):\n",
    "        proj, _ = cv2.projectPoints(ch_corners, rvec, tvec, K, dist)\n",
    "        err = np.linalg.norm(proj.reshape(-1,2) - ch_corners.reshape(-1,2), axis=1)\n",
    "        errors.extend(err)\n",
    "\n",
    "errors = np.array(errors)\n",
    "print(f\"Total points: {len(errors)}, mean error = {errors.mean():.4f} px\")\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(errors, bins=50, range=(0, np.percentile(errors,99)))\n",
    "plt.title(\"Reprojection Error Distribution\")\n",
    "plt.xlabel(\"Error (px)\")\n",
    "plt.ylabel(\"Number of points\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather radial distances and corresponding errors\n",
    "radial = []\n",
    "for fname in []: pass  # placeholder; we can reuse corners or compute directly\n",
    "\n",
    "# Instead, recompute radial distances from principal point:\n",
    "cx, cy = K[0,2], K[1,2]\n",
    "pts = []\n",
    "errs = []\n",
    "if mode == 'checker':\n",
    "    for objp, imgp, rvec, tvec in zip(objpoints, imgpoints, rvecs, tvecs):\n",
    "        proj, _ = cv2.projectPoints(objp, rvec, tvec, K, dist)\n",
    "        flat_proj = proj.reshape(-1,2)\n",
    "        flat_imgp = imgp.reshape(-1,2)\n",
    "        for p_proj, p_img in zip(flat_proj, flat_imgp):\n",
    "            radial.append(np.linalg.norm(p_img - np.array([cx, cy])))\n",
    "            errs.append(np.linalg.norm(p_proj - p_img))\n",
    "elif mode == 'charuco':\n",
    "    for ch_corners, rvec, tvec in zip(corners, rvecs, tvecs):\n",
    "        proj, _ = cv2.projectPoints(ch_corners, rvec, tvec, K, dist)\n",
    "        flat_proj = proj.reshape(-1,2)\n",
    "        flat_corn = ch_corners.reshape(-1,2)\n",
    "        for p_proj, p_corn in zip(flat_proj, flat_corn):\n",
    "            radial.append(np.linalg.norm(p_corn - np.array([cx, cy])))\n",
    "            errs.append(np.linalg.norm(p_proj - p_corn))\n",
    "\n",
    "radial = np.array(radial)\n",
    "errs   = np.array(errs)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(radial, errs, s=2, alpha=0.3)\n",
    "plt.title(\"Radial Error vs. Distance from Center\")\n",
    "plt.xlabel(\"Radius (px)\")\n",
    "plt.ylabel(\"Error (px)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib = {\n",
    "    'K': {'data': K.tolist(), 'rows':3, 'cols':3},\n",
    "    'D': {'data': dist.ravel().tolist(), 'rows':1, 'cols':len(dist.ravel())}\n",
    "}\n",
    "with open(YAML_OUT, 'w') as f:\n",
    "    yaml.dump(calib, f)\n",
    "print(f\"Saved intrinsics to {YAML_OUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlay: Detected vs. Reprojected Corners\n",
    "\n",
    "Now that we have our camera matrix **K** and distortion **d**, let's take one example image and:\n",
    "\n",
    "1. Plot the **detected** corners in **green**.  \n",
    "2. Project the corresponding 3D object points back into the image and plot these **reprojected** corners in **red**.  \n",
    "\n",
    "Ideally they should coincide. Large offsets highlight local calibration errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the middle image for visualization\n",
    "img_files = sorted(os.path.join('..','data',f) for f in os.listdir('../data') if f.endswith('.jpg'))\n",
    "valid_files = data['valid_files']\n",
    "img_idx = len(valid_files)//3\n",
    "viz_path = valid_files[img_idx]\n",
    "viz_img = cv2.imread(os.path.join('..','data', os.path.basename(viz_path)))\n",
    "gray_viz = cv2.cvtColor(viz_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# retrieve one set of object & image points for checkerboard, or charuco\n",
    "if mode == 'checker':\n",
    "    objp = objpoints[img_idx]         # 3D points\n",
    "    imgp = imgpoints[img_idx].reshape(-1,2)  # detected 2D points\n",
    "    rvec, tvec = rvecs[img_idx], tvecs[img_idx]\n",
    "elif mode == 'charuco':\n",
    "    # convert to 3D by adding Z=0\n",
    "    ch_c = corners[img_idx].reshape(-1,2)\n",
    "    objp = np.hstack([ch_c, np.zeros((len(ch_c),1))])\n",
    "    imgp = ch_c\n",
    "    rvec, tvec = rvecs[img_idx], tvecs[img_idx]\n",
    "\n",
    "# project objp back into pixel space\n",
    "proj_pts, _ = cv2.projectPoints(objp, rvec, tvec, K, dist)\n",
    "proj_pts = proj_pts.reshape(-1,2)\n",
    "\n",
    "# overlay\n",
    "vis = viz_img.copy()\n",
    "for (x,y), (u,v) in zip(imgp, proj_pts):\n",
    "    cv2.circle(vis, (int(x),int(y)), 4, (0,255,0), 2)  # green = detected\n",
    "    cv2.circle(vis, (int(u),int(v)), 3, (0,0,255), 2)  # red   = reprojected\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Green: detected corners     Red: reprojected corners\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Are We Comparing Between Green and Red Dots?\n",
    "\n",
    "This visualization shows two sets of 2D points plotted over the image:\n",
    "\n",
    "- **Green dots**: These are **detected image points** — pixel locations where the checkerboard corners were found using OpenCV's `findChessboardCorners()` (or ChArUco equivalent). These are your \"ground truth\" 2D detections.\n",
    "- **Red dots**: These are **reprojected points** — predicted pixel positions obtained by projecting the known 3D board corners using your estimated camera intrinsics and extrinsics. These come from `cv2.projectPoints()`.\n",
    "\n",
    "---\n",
    "\n",
    "### Step-by-Step Pipeline\n",
    "\n",
    "#### 1. **Detect corners in the image (green dots)**\n",
    "\n",
    "You detect 2D points in the captured image using:\n",
    "```python\n",
    "ret, corners = cv2.findChessboardCorners(gray, pattern_size, ...)\n",
    "```\n",
    "\n",
    "This gives you a list of 2D image coordinates:\n",
    "$$\\{(u_i, v_i)\\}_{i=1}^{N}$$\n",
    "\n",
    "#### 2. **Define the known 3D object points**\n",
    "\n",
    "For a checkerboard with num_x × num_y squares, there are (num_x - 1) × (num_y - 1) inner corners. We define these points on a 2D plane (Z = 0), scaled by the square size:\n",
    "$$\\{(X_i, Y_i, 0)\\}_{i=1}^{N}$$\n",
    "\n",
    "#### 3. **Calibrate the camera**\n",
    "\n",
    "You solve for the camera intrinsics (K), distortion coefficients (d), and per-frame extrinsics (R, t) using:\n",
    "\n",
    "```python\n",
    "cv2.calibrateCamera(...)\n",
    "```\n",
    "\n",
    "This fits the projection model:\n",
    "$$\\mathbf{P} = \\mathbf{K} [\\mathbf{R} \\mid \\mathbf{t}]$$\n",
    "and distortion model (radial + tangential) by minimizing:\n",
    "$$\\sum_{i} \\left| (u_i, v_i) - \\Pi(\\mathbf{K}, \\mathbf{R}, \\mathbf{t}; X_i) \\right|^2$$\n",
    "\n",
    "#### 4. **Reproject the 3D points into image space (red dots)**\n",
    "\n",
    "Using the estimated calibration parameters, you reproject the known 3D object points into the image:\n",
    "\n",
    "```python\n",
    "proj_pts = cv2.projectPoints(objp, rvec, tvec, K, dist)\n",
    "```\n",
    "\n",
    "This yields predicted 2D points:\n",
    "$$\\{(\\hat{u}_i, \\hat{v}_i)\\}_{i=1}^{N}$$\n",
    "\n",
    "---\n",
    "\n",
    "### Why Are the Red and Green Dots Different?\n",
    "\n",
    "They won't perfectly overlap, because the model is an approximation and the input data is noisy:\n",
    "- **Detection noise**: Even subpixel corner detection is affected by blur, lighting, and resolution.\n",
    "- **Model mismatch**: The distortion model may not fully capture the lens behavior, especially at the periphery.\n",
    "- **Limited coverage**: If certain viewpoints (e.g. tilted, close-up, or edge shots) are missing, the model is under-constrained in those areas.\n",
    "- **Numerical approximation**: Optimization has residual error even after convergence.\n",
    "\n",
    "---\n",
    "\n",
    "### Reprojection Error\n",
    "\n",
    "The difference between red and green dots is called the reprojection error — the distance between where the model says a corner should be and where it was actually detected.\n",
    "- **Good calibration**: < 0.5 px mean reprojection error\n",
    "- **Precision calibration**: < 0.3 px\n",
    "- **Bad calibration**: > 1.0 px — likely poor data, blur, or mismatch in square size or pattern\n",
    "\n",
    "---\n",
    "\n",
    "### How to Improve Alignment\n",
    "- **Ensure accurate board specs**: match pattern_size to the printed board.\n",
    "- **Use consistent indexing**: Make sure you're overlaying red/green dots for the same image.\n",
    "- **Capture diverse viewpoints**: Boards at various angles, distances, and edge positions.\n",
    "- **Drop outlier images**: Recompute calibration without frames that have large reprojection error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try-it-yourself ✏️  \n",
    "Use the sliders below to perturb the **radial (k₁, k₂)** and **tangential (p₁, p₂)** distortion\n",
    "coefficients and watch how the *red* re-projected corners shift relative to the *green*\n",
    "detected ones.\n",
    "\n",
    "* Questions to think about  \n",
    "  1. When you nudge **k₁** positively, which image region moves the most?  \n",
    "  2. Which coefficient mainly shears the pattern rather than radial-expands it?  \n",
    "  3. At what coefficient values do the re-projected dots best coincide with the detections?  \n",
    "\n",
    "Remember: in a real calibration workflow we optimise these coefficients so that the\n",
    "re-projection error (pixel distance between the two sets of dots) is minimised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install ipywidgets\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive, HBox, VBox, Button\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# --- objects prepared earlier -----------------\n",
    "# K, dist, objp, imgp, rvec, tvec, viz_img\n",
    "# ---------------------------------------------\n",
    "\n",
    "# ❶ Create the sliders\n",
    "\n",
    "def make_slider(label, value, coarse_factor=3.0, fine_step=1e-3,\n",
    "                hard_max=5.0):\n",
    "    \"\"\"\n",
    "    Return a FloatSlider centred at 0 whose ±range equals\n",
    "    min(hard_max, coarse_factor*|value|) but never < 0.05.\n",
    "    \"\"\"\n",
    "    span = max(abs(value) * coarse_factor, 0.05)\n",
    "    span = min(span, hard_max)\n",
    "    return widgets.FloatSlider(\n",
    "        value=float(value),\n",
    "        min=-span,\n",
    "        max= span,\n",
    "        step=fine_step,\n",
    "        description=label\n",
    "    )\n",
    "\n",
    "# 1️⃣ Sliders for all five coefficients\n",
    "k1_slider = make_slider('k₁', dist[0][0])\n",
    "k2_slider = make_slider('k₂', dist[0][1])\n",
    "p1_slider = make_slider('p₁', dist[0][2], coarse_factor=3.0, fine_step=1e-4, hard_max=0.2)\n",
    "p2_slider = make_slider('p₂', dist[0][3], coarse_factor=3.0, fine_step=1e-4, hard_max=0.2)\n",
    "k3_slider = make_slider('k₃', dist[0][4], coarse_factor=1.5, fine_step=1e-2, hard_max=10)\n",
    "\n",
    "# 2️⃣ Reset button\n",
    "reset_btn = Button(description=\"Reset ↺\", tooltip=\"Restore calibrated values\")\n",
    "\n",
    "def reset_sliders(_):\n",
    "    for s, val in zip([k1_slider, k2_slider, p1_slider, p2_slider, k3_slider], dist[0]):\n",
    "        s.value = float(val)\n",
    "reset_btn.on_click(reset_sliders)\n",
    "\n",
    "# 3️⃣ Projection visualisation\n",
    "def show_projection(k1, k2, p1, p2, k3):\n",
    "    d = np.array([k1, k2, p1, p2, k3], dtype=np.float64)\n",
    "    proj_pts, _ = cv2.projectPoints(objp, rvec, tvec, K, d)\n",
    "    proj_pts = proj_pts.reshape(-1, 2)\n",
    "\n",
    "    vis = viz_img.copy()\n",
    "    for (x, y), (u, v) in zip(imgp, proj_pts):\n",
    "        cv2.circle(vis, (int(x), int(y)), 4, (0, 255, 0), 2)   # detected\n",
    "        cv2.circle(vis, (int(u), int(v)), 3, (0,   0, 255), 2) # re-projected\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 4️⃣ Bind sliders to plotting function\n",
    "interactive_plot = interactive(\n",
    "    show_projection,\n",
    "    k1=k1_slider, k2=k2_slider, k3=k3_slider,\n",
    "    p1=p1_slider, p2=p2_slider\n",
    ")\n",
    "\n",
    "# 5️⃣ Display UI\n",
    "display(VBox([HBox([reset_btn]), interactive_plot]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do the distortion coefficients actually do?\n",
    "\n",
    "| Symbol | Name | Typical visual effect  |\n",
    "| ------ | ---- | ---------------------  |\n",
    "| **k₁** | 1st radial distortion | Barrel / pincushion curvature that grows ∝ *r²* |\n",
    "| **k₂** | 2nd radial distortion | Higher-order tweak that exaggerates the edge warping introduced by **k₁** |\n",
    "| **k₃** | 3rd radial distortion | Cubic radial term—dominates in the extreme corners when **k₁**, **k₂** can’t fully correct |\n",
    "| **p₁** | Tangential (x-shear) | Skews dots left/right when the lens & sensor are not perfectly parallel |\n",
    "| **p₂** | Tangential (y-shear) | Skews dots up/down under the same mis-alignment |\n",
    "\n",
    "*Here \\(r^2 = x^2 + y^2\\) is the squared, normalised image-plane radius.*\n",
    "\n",
    "**How to interpret the sliders**\n",
    "\n",
    "* If the red dots form a symmetric bulge or pinch, adjust **k₁**, **k₂**, or **k₃** (radial terms).  \n",
    "* If they lean or shear in one direction, tweak **p₁** or **p₂** (tangential terms).  \n",
    "* Press **Reset ↺** any time to return to the calibrated optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Side-by-side: Original vs. Undistorted\n",
    "\n",
    "Next, we’ll undistort the same image using our intrinsics and plot it alongside the original.  \n",
    "Notice how straight lines near the border are “pulled” back into alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undistort entire image\n",
    "h, w = gray_viz.shape\n",
    "newK, _ = cv2.getOptimalNewCameraMatrix(K, dist, (w,h), 1)\n",
    "undist = cv2.undistort(viz_img, K, dist, None, newK)\n",
    "\n",
    "# plot side by side\n",
    "fig, axes = plt.subplots(1,2, figsize=(12,5))\n",
    "axes[0].imshow(cv2.cvtColor(viz_img, cv2.COLOR_BGR2RGB))\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(cv2.cvtColor(undist, cv2.COLOR_BGR2RGB))\n",
    "axes[1].set_title(\"Undistorted\")\n",
    "axes[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distortion Vector Field\n",
    "\n",
    "Let’s visualize how each pixel is displaced by the distortion model.  \n",
    "We’ll sample a coarse grid (e.g. every 40 px), undistort those points,  \n",
    "and draw arrows from original → undistorted positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grid of points\n",
    "stride = 40\n",
    "Y, X = np.mgrid[0:h:stride, 0:w:stride].reshape(2,-1)\n",
    "grid = np.vstack([X, Y]).T.astype(np.float32).reshape(-1,1,2)\n",
    "\n",
    "# undistort these grid points\n",
    "und_grid = cv2.undistortPoints(grid, K, dist, P=K).reshape(-1,2)\n",
    "\n",
    "# plot arrows on the original image\n",
    "field_vis = viz_img.copy()\n",
    "for (x,y), (u,v) in zip(grid.reshape(-1,2), und_grid):\n",
    "    cv2.arrowedLine(field_vis, (int(x),int(y)), (int(u),int(v)),\n",
    "                    color=(255,0,0), thickness=1, tipLength=0.3)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(cv2.cvtColor(field_vis, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Distortion Vector Field (blue arrows)\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The arrows indicate the magnitude and direction of distortion across the field—longer arrows at the periphery reflect stronger barrel distortion.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Heatmap Across All Images\n",
    "\n",
    "Finally, let’s accumulate reprojection errors spatially over every image.  \n",
    "We’ll bin each projected point by its undistorted pixel location and color‐code the average error in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather all reproj errors + undistorted locations\n",
    "all_u = []; all_v = []; all_e = []\n",
    "\n",
    "for i in range(len(rvecs)):\n",
    "    if mode == 'checker':\n",
    "        pts2d = imgpoints[i].reshape(-1,2)\n",
    "        objp_i = objpoints[i]\n",
    "    else:\n",
    "        pts2d = corners[i].reshape(-1,2)\n",
    "        objp_i = np.hstack([pts2d, np.zeros((len(pts2d),1))])\n",
    "\n",
    "    # project and undistort\n",
    "    proj2d, _ = cv2.projectPoints(objp_i, rvecs[i], tvecs[i], K, dist)\n",
    "    proj2d = proj2d.reshape(-1,2)\n",
    "    und2d = cv2.undistortPoints(pts2d.reshape(-1,1,2), K, dist, P=K).reshape(-1,2)\n",
    "\n",
    "    errs = np.linalg.norm(proj2d - pts2d, axis=1)\n",
    "    all_u.extend(und2d[:,0]); all_v.extend(und2d[:,1]); all_e.extend(errs)\n",
    "\n",
    "all_u = np.array(all_u); all_v = np.array(all_v); all_e = np.array(all_e)\n",
    "\n",
    "# bin into a heatmap\n",
    "nbin = 50\n",
    "xi = np.linspace(0, w, nbin)\n",
    "yi = np.linspace(0, h, nbin)\n",
    "heatmap, _, _ = np.histogram2d(all_v, all_u, bins=[yi, xi], weights=all_e)\n",
    "counts, _, _  = np.histogram2d(all_v, all_u, bins=[yi, xi])\n",
    "heatmap = np.divide(heatmap, counts, out=np.zeros_like(heatmap), where=counts>0)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.imshow(heatmap, origin='lower', extent=[0,w,0,h], cmap='hot')\n",
    "plt.colorbar(label='Mean reprojection error (px)')\n",
    "plt.title(\"Spatial Heatmap of Reprojection Error\")\n",
    "plt.xlabel(\"u (px)\"); plt.ylabel(\"v (px)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The heatmap shows where your calibration struggles most; hot regions near the border often point to insufficient distortion modeling or corner detection accuracy.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Next:**  \n",
    "- Use these intrinsics in `measure_object.py` to perform metric checks.  \n",
    "- Switch to the other board type (checker ↔ ChArUco) and compare mean errors.  \n",
    "- Commit `captured_points/intrinsics.yml` to GitHub for TA review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
